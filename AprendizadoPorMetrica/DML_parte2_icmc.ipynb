{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHujA20wJtmR"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import imutils\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import dlib\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image,ImageStat"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-telegram-bot --upgrade"
      ],
      "metadata": {
        "id": "P4Jx1IP_Sj8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLsvdv97BlZw"
      },
      "outputs": [],
      "source": [
        "main_dir = '/content/drive/MyDrive/tutorial_dml'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DwhRpIVBcAN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iA-xsdJmAsQl"
      },
      "outputs": [],
      "source": [
        "os.chdir(main_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G1iyM7HAUHj"
      },
      "source": [
        "# Alinhamento e crop das faces"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -N http://dlib.net/files/shape_predictor_5_face_landmarks.dat.bz2"
      ],
      "metadata": {
        "id": "mcR8RTo_DOKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!bunzip2 \"shape_predictor_5_face_landmarks.dat.bz2\""
      ],
      "metadata": {
        "id": "aPt5DzKsDbjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "L-LEz9hEDn-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_file_path = main_dir+\"/pessoas/IMG_20220827_155011.jpg\"\n"
      ],
      "metadata": {
        "id": "6AhdTU82IBTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_file_path.split('/')[-1]"
      ],
      "metadata": {
        "id": "3DsUvGWEICTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "6s6tdN8yLpi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.isdir('cropped'):os.mkdir('cropped')"
      ],
      "metadata": {
        "id": "-xLQm-w7B7DA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor_path = \"shape_predictor_5_face_landmarks.dat\"\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "sp = dlib.shape_predictor(predictor_path)\n",
        "\n",
        "# Load the image using Dlib\n",
        "\n",
        "def crop_images():\n",
        "    for file_name in os.listdir('pessoas'):\n",
        "        face_file_path = main_dir+f'/pessoas/{file_name}'\n",
        "        print(face_file_path)\n",
        "        img = dlib.load_rgb_image(face_file_path)\n",
        "\n",
        "        # Ask the detector to find the bounding boxes of each face. The 1 in the\n",
        "        # second argument indicates that we should upsample the image 1 time. This\n",
        "        # will make everything bigger and allow us to detect more faces.\n",
        "        dets = detector(img, 1)\n",
        "\n",
        "        num_faces = len(dets)\n",
        "        if num_faces == 0:\n",
        "            print(\"Sorry, there were no faces found in '{}'\".format(face_file_path))\n",
        "        else:\n",
        "            # Find the 5 face landmarks we need to do the alignment.\n",
        "            faces = dlib.full_object_detections()\n",
        "            for detection in dets:\n",
        "                faces.append(sp(img, detection))\n",
        "\n",
        "\n",
        "\n",
        "            # Get the aligned face images\n",
        "            # Optionally: \n",
        "            images = dlib.get_face_chips(img, faces, size=160, padding=0.25)\n",
        "            #images = dlib.get_face_chips(img, faces, size=320)\n",
        "            for i,image in enumerate(images):\n",
        "                #im_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "                im_pil = Image.fromarray(image)\n",
        "                im_pil.save(f\"cropped/{face_file_path.split('/')[-1].replace('.jpg','')}_{i}.jpg\")\n",
        "                \n",
        "\n",
        "# It is also possible to get a single chip\n",
        "#image = dlib.get_face_chip(img, faces[0])\n"
      ],
      "metadata": {
        "id": "KpzFpqt8DI7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#crop_images()"
      ],
      "metadata": {
        "id": "XbUBDnyALm8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIthRPB7919X"
      },
      "source": [
        "Após o crop, separe as faces por pessoa onde cada pessoa é uma pasta\n",
        "\n",
        "    tutorial_dml/familia/takashi\n",
        "                         /patricia\n",
        "                         /naomi\n",
        "                         /takeo\n",
        "                         /pai\n",
        "                         /mae    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMsGmvfCKdRW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfjVAJ1M-X22"
      },
      "source": [
        "# Identificação das faces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9pZIMLT-dG3"
      },
      "source": [
        "## Preparação do ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98qo_iRy-bQE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79VWWVmn-jwm"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FMYPuu8-lo3"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/drive/MyDrive/tutorial_dml/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aw0mo_iq_Is9"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDUrFQhP_MaW"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/deepinsight/insightface.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWFurFHx_T0G"
      },
      "outputs": [],
      "source": [
        "os.chdir(\"/content/drive/MyDrive/tutorial_dml/insightface/recognition/arcface_torch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiW4CmOO_WSo"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSoKxpum_XrN"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirement.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcEFwNPc_vMf"
      },
      "source": [
        "## Carga do modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNcWwaUn_ZDe"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from backbones import get_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmE8I9Pl_iZ2"
      },
      "outputs": [],
      "source": [
        "model = get_model('r50', fp16=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4aTU5nr_lnu"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVAKr2zy_nnO"
      },
      "outputs": [],
      "source": [
        "!gdown 17dp-EUhvX4K-g8s0ce8ODRNTiaYjTC_D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "in9wzs6T_qh_"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load('backbone.pth'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2JchcMgA6cE"
      },
      "source": [
        "## Preparação do conjunto de dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXQVqptt_-PP"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTJT0hrWBBas"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.Resize((130,130)),\n",
        "                                transforms.CenterCrop((112,112)),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "                            ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TydvJcbjBDID"
      },
      "outputs": [],
      "source": [
        "ds = torchvision.datasets.ImageFolder(\"/content/drive/MyDrive/tutorial_dml/familia3\",transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Scq1n7DBE1K"
      },
      "outputs": [],
      "source": [
        "len(ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxSWD4IZBJBw"
      },
      "outputs": [],
      "source": [
        "dl = torch.utils.data.DataLoader(ds,batch_size=len(ds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gb6uZkDRBLOH"
      },
      "outputs": [],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KbUF97gBMan"
      },
      "outputs": [],
      "source": [
        "x,y = next(iter(dl))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "id": "NpamnXRmDvvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Beyh8NpBSIS"
      },
      "source": [
        "## Construção dos embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o11gu78VBRGP"
      },
      "outputs": [],
      "source": [
        "pred = model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HuxrTjDBW6y"
      },
      "outputs": [],
      "source": [
        "pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRfyuuuuBfw6"
      },
      "outputs": [],
      "source": [
        "xall = np.asarray(pred.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDsbWHYhBhS6"
      },
      "source": [
        "## Splits de treino e teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGR-tErGBkhO"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXwQyndSBnhC"
      },
      "outputs": [],
      "source": [
        "xtrain, xtest, ytrain, ytest = train_test_split(xall, y, test_size=0.33, random_state=42,stratify=np.array(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdtPCow7Bo-n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McF44sH8BqzN"
      },
      "source": [
        "## Treino e execução do knn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGZs7XJdB7gC"
      },
      "outputs": [],
      "source": [
        "import sklearn.neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFNXrQ0tB4R3"
      },
      "outputs": [],
      "source": [
        "knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors=1,weights='distance')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4wrnGk7B77n"
      },
      "outputs": [],
      "source": [
        "knn.fit(xtrain,ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWvHsSVeB9O3"
      },
      "outputs": [],
      "source": [
        "pred = knn.predict(xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5P2sAgsB-6o"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRFEsDG5B_38"
      },
      "source": [
        "## Avaliação do modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSJL4GHFCBkX"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfNuywpVCG2p"
      },
      "outputs": [],
      "source": [
        "print(metrics.classification_report(ytest,pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjmwipkHCHlv"
      },
      "outputs": [],
      "source": [
        "ds.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFh2QDhrCJCQ"
      },
      "outputs": [],
      "source": [
        "print(metrics.confusion_matrix(ytest,pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJhFxkpuCLJ3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSdthO8dChxR"
      },
      "source": [
        "# Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77OAo27AH6ED"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbDMFr52CjPo"
      },
      "outputs": [],
      "source": [
        "!pip install python-telegram-bot --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pM_wJHIPIJ7F"
      },
      "outputs": [],
      "source": [
        "from telegram.ext import Updater, Filters, MessageHandler, CommandHandler\n",
        "import requests\n",
        "import re\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image,ImageStat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LijUFzwLIOXe"
      },
      "outputs": [],
      "source": [
        "knn.fit(xall, y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor_path = main_dir+ \"/shape_predictor_5_face_landmarks.dat\"\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "sp = dlib.shape_predictor(predictor_path)\n",
        "\n",
        "# Load the image using Dlib\n",
        "\n",
        "def crop_images(image_file):\n",
        "\n",
        "    face_file_path = image_file\n",
        "    print(face_file_path)\n",
        "    img = dlib.load_rgb_image(face_file_path)\n",
        "\n",
        "    # Ask the detector to find the bounding boxes of each face. The 1 in the\n",
        "    # second argument indicates that we should upsample the image 1 time. This\n",
        "    # will make everything bigger and allow us to detect more faces.\n",
        "    dets = detector(img, 1)\n",
        "    crop_found = []\n",
        "    num_faces = len(dets)\n",
        "    if num_faces == 0:\n",
        "        print(\"Sorry, there were no faces found in '{}'\".format(face_file_path))\n",
        "    else:\n",
        "        # Find the 5 face landmarks we need to do the alignment.\n",
        "        faces = dlib.full_object_detections()\n",
        "        for detection in dets:\n",
        "            faces.append(sp(img, detection))\n",
        "\n",
        "\n",
        "\n",
        "        # Get the aligned face images\n",
        "        # Optionally: \n",
        "        images = dlib.get_face_chips(img, faces, size=160, padding=0.25)\n",
        "        #images = dlib.get_face_chips(img, faces, size=320)\n",
        "        for i,image in enumerate(images):\n",
        "            #im_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "            im_pil = Image.fromarray(image)\n",
        "            crop_found.append(im_pil)\n",
        "    return crop_found"
      ],
      "metadata": {
        "id": "6nQqRgyuNXJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycOu5OBnK8-C"
      },
      "outputs": [],
      "source": [
        "file_name = \"IMG_20220827_155011.jpg\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-Zf6y4qWmBU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2x2rdTSKuIU"
      },
      "outputs": [],
      "source": [
        "crops = crop_images(\"/content/drive/MyDrive/tutorial_dml/pessoas/\"+file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgHI-gjsS4IZ"
      },
      "outputs": [],
      "source": [
        "nomes = np.asarray(ds.classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRQ7gvlwR1DO"
      },
      "outputs": [],
      "source": [
        "def get_person_ids(crops):\n",
        "    imglist = []\n",
        "    for img in crops:\n",
        "        imglist.append(transform(img).unsqueeze(0))\n",
        "    x = torch.cat(imglist,axis=0)\n",
        "    embeddings = model(x)\n",
        "    embeddings = np.asarray(embeddings.tolist())\n",
        "    prob_pessoas = knn.predict_proba(embeddings)\n",
        "    id_pessoas = prob_pessoas.argmax(axis=1)\n",
        "    return nomes[id_pessoas]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7Fw7e7-S7eW"
      },
      "outputs": [],
      "source": [
        "pessoas_identificadas=get_person_ids(crops)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvwG4EqsUs16"
      },
      "outputs": [],
      "source": [
        "print(f'{pessoas_identificadas}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_WYehj3cV-5"
      },
      "outputs": [],
      "source": [
        "len(crops)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6XeDLnAUTn9"
      },
      "outputs": [],
      "source": [
        "nomes = np.asarray(ds.classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptUJTjaaWw3A"
      },
      "outputs": [],
      "source": [
        "dir_bot = \"/content/drive/MyDrive/tutorial_dml/imgs_recebidas\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYCHovkNcPdk"
      },
      "outputs": [],
      "source": [
        "dir_pessoas = \"/content/drive/MyDrive/tutorial_dml/imgs_pessoas\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClabsALheBAZ"
      },
      "outputs": [],
      "source": [
        "if not os.path.isdir(dir_bot): os.mkdir(dir_bot)\n",
        "if not os.path.isdir(dir_pessoas): os.mkdir(dir_pessoas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNPrWCS1T6Bo"
      },
      "outputs": [],
      "source": [
        "def encontra_pessoas(image_file):\n",
        "    crops = crop_images(dir_bot+os.sep+image_file)\n",
        "    for i,img in enumerate(crops):\n",
        "        img.save(dir_pessoas+f\"/{i}.jpg\")\n",
        "\n",
        "    return get_person_ids(crops)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSD5fU5maLhf"
      },
      "outputs": [],
      "source": [
        "import pdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnvXnb8mHNQK"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "def image_handler(update, context):\n",
        "    file = update.message.photo[-1].file_id\n",
        "    obj = context.bot.get_file(file)\n",
        "    os.chdir(dir_bot)\n",
        "    path = obj.download()\n",
        "    pessoas_identificadas = encontra_pessoas(path)\n",
        "    print(pessoas_identificadas)\n",
        "    for i, nome_pessoa in enumerate(pessoas_identificadas):\n",
        "        update.message.reply_photo(open(dir_pessoas+f\"/{i}.jpg\",\"rb\"))\n",
        "        update.message.reply_text(f'{nome_pessoa}')\n",
        "\n",
        "def start(update, context):\n",
        "  return update.message.reply_text('Seja bem vindo ao reconhecedor facial ')\n",
        "\n",
        "def main():\n",
        "    keytelegram = \"XXXX\" # criar a sua key\n",
        "    updater = Updater(keytelegram)\n",
        "    dp = updater.dispatcher\n",
        "    dp.add_handler(MessageHandler(Filters.photo, image_handler))\n",
        "    dp.add_handler(CommandHandler('start', start))\n",
        "    updater.start_polling()\n",
        "    updater.idle()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlTwGhLYL1zM"
      },
      "outputs": [],
      "source": [
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTLlk3BmVlZE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}