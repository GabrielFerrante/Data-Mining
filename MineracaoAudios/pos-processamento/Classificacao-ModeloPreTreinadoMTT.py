# -*- coding: utf-8 -*-
"""Mineração de Áudio - Modelo Pré-Treinado para Músicas.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BEuzVbvcU7arKtLrP5q098Rx6gFNCC0-

# Instalando e importando bibliotecas
"""

#!pip install musicnn

#!git clone https://github.com/jordipons/musicnn

"""# Usando o modelo pré-treinando para tag de música"""

file_name = './musicnn/audio/joram-moments_of_clarity-08-solipsism-59-88.mp3'
from IPython.display import Audio
Audio(url="https://github.com/jordipons/musicnn/raw/master/audio/joram-moments_of_clarity-08-solipsism-59-88.mp3")

from musicnn.tagger import top_tags
tags = top_tags(file_name, model='MTT_musicnn', topN=10)

"""# Evolução temporal das tags (taggram)"""

from musicnn.extractor import extractor

taggram, tags = extractor(file_name, model='MTT_musicnn', extract_features=False)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import numpy as np
import matplotlib.pyplot as plt

in_length = 3 # seconds  by default, the model takes inputs of 3 seconds with no overlap

plt.rcParams["figure.figsize"] = (10,8) # set size of the figures
fontsize = 12 # set figures font size

fig, ax = plt.subplots()

# title
ax.title.set_text('Taggram')
ax.title.set_fontsize(fontsize)

# x-axis title
ax.set_xlabel('(seconds)', fontsize=fontsize)

# y-axis
y_pos = np.arange(len(tags))
ax.set_yticks(y_pos)
ax.set_yticklabels(tags, fontsize=fontsize-1)

# x-axis
x_pos = np.arange(taggram.shape[0])
x_label = np.arange(in_length/2, in_length*taggram.shape[0], 3)
ax.set_xticks(x_pos)
ax.set_xticklabels(x_label, fontsize=fontsize)

# depict taggram
ax.imshow(taggram.T, interpolation=None, aspect="auto")
plt.show()

"""# Extraindo características das músicas (embeddings)"""

from musicnn.extractor import extractor
taggram, tags, features = extractor(file_name, model='MTT_musicnn', extract_features=True)

import numpy as np
frontend_features = np.concatenate([features['temporal'], features['timbral']], axis=1)

frontend_features

frontend_features.shape

import pandas as pd

pd.DataFrame(frontend_features)

"""# Testando com outra música"""

file_name = './musicnn/audio/TRWJAZW128F42760DD_test.mp3'
from IPython.display import Audio
Audio(url="https://github.com/jordipons/musicnn/raw/master/audio/TRWJAZW128F42760DD_test.mp3")

from musicnn.extractor import extractor
taggram, tags, features = extractor(file_name, model='MTT_musicnn', extract_features=True)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import numpy as np
import matplotlib.pyplot as plt

in_length = 3 # seconds  by default, the model takes inputs of 3 seconds with no overlap

plt.rcParams["figure.figsize"] = (10,8) # set size of the figures
fontsize = 12 # set figures font size

fig, ax = plt.subplots()

# title
ax.title.set_text('Taggram')
ax.title.set_fontsize(fontsize)

# x-axis title
ax.set_xlabel('(seconds)', fontsize=fontsize)

# y-axis
y_pos = np.arange(len(tags))
ax.set_yticks(y_pos)
ax.set_yticklabels(tags, fontsize=fontsize-1)

# x-axis
x_pos = np.arange(taggram.shape[0])
x_label = np.arange(in_length/2, in_length*taggram.shape[0], 3)
ax.set_xticks(x_pos)
ax.set_xticklabels(x_label, fontsize=fontsize)

# depict taggram
ax.imshow(taggram.T, interpolation=None, aspect="auto")
plt.show()

import numpy as np
import pandas as pd

frontend_features = np.concatenate([features['temporal'], features['timbral']], axis=1)

pd.DataFrame(frontend_features)

